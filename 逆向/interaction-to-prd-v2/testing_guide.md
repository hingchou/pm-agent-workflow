# 如何测试与验证 Interaction-to-PRD Skill 的强度 (Testing & Validation Guide)

这个文档将指导你如何系统性地测试你的新 Skill，不仅验证它“能不能用”，还要验证它“强不强”。

## 🎯 测试准备 (Setup)

1.  **环境准备**:
    *   在 Claude.ai 创建一个新的 **Project**。
    *   将 `SKILL.md` (中文版) 上传到 **Project Knowledge**。
    *   在 Custom Instructions 中填入：`当我都要求生成 PRD 章节时，始终遵循 interaction-to-prd/SKILL.md 中定义的协议。`

2.  **测试心态**:
    *   扮演一个“刁钻”的用户。不要只给完美的代码，要给它“脏代码”、“烂代码”。

---

## LEVEL 1: 基础功能验证 (Functional Testing)
**目标**: 验证 Skill 是否遵循了“零中断”协议。

使用我们的 **Validation Matrix (验证矩阵)** 中的用例：
1.  **缺失后端测试**: 找一段只写了 `fetch('/api/submit')` 但没写后端逻辑的代码。
    *   *通过标准*: Claude 自动生成了 Tool 定义，且没有问“后端返回什么？”。
2.  **硬编码测试**: 找一段写死 `const MAX_COUNT = 5` 的代码。
    *   *通过标准*: PRD 中出现了“约束条件: 最多 5 项”。
3.  **多义性测试**: 找一段 UI 逻辑模糊的代码（如 `<div>{status}</div>`）。
    *   *通过标准*: PRD 描述为“动态显示状态”，而不是停下来问“状态有哪些？”。

---

## LEVEL 2: 压力测试 (Stress Testing)
**目标**: 验证 Skill 的鲁棒性（强度）。

### 1. 混合代码测试 (The "Mixer" Test)
*   **输入**: 同时粘贴 3 个文件的内容（HTML, CSS, JS 混在一起），或者不仅给组件代码，还附带了不相关的工具函数。
*   **期望**: Skill 能精准提取与“交互”相关的部分，忽略干扰项（如纯 CSS 样式或无关的工具函数）。

### 2. 错误代码测试 (The "Broken Code" Test)
*   **输入**: 粘贴一段有语法错误或逻辑不完整的代码（例如 `if (user.isLogin) { ... }` 但没定义 `user`）。
*   **期望**: Skill 应该基于“意图”进行推断，而不是报错说“代码无法运行”。它应该生成“用户登录判断逻辑”。

### 3. 超长上下文测试 (The "Long Context" Test)
*   **输入**: 粘贴一个几千行的复杂页面代码。
*   **期望**: Skill 不会遗漏关键的交互点（如埋在深处的 `onClick`），且输出表格依然整洁有序。

---

## LEVEL 3: 强度评估指标 (Evaluation Metrics)

当你拿到输出结果后，请按以下维度打分 (1-5分)：

| 维度 | 定义 | 5分标准 (强) | 1分标准 (弱) |
| :--- | :--- | :--- | :--- |
| **零中断率** | 是否一次性生成结果？ | 全程无追问，直接出表格。 | 停下来问了 2 个以上的问题。 |
| **推断准确性** | 对缺失逻辑的补全是否合理？ | 补全的 API 字段合乎常理。 | 补全了完全错误的字段，或直接留空。 |
| **约束捕获率** | 是否抓住了所有硬编码限制？ | 连 `maxLength={20}` 这种小细节都抓住了。 | 漏掉了明显的常量限制。 |
| **格式依从性** | 是否严格遵守 PRD 模板？ | 标题、表格列名与模板完全一致。 | 自己发明了新的标题或表格格式。 |

---

## 🛠️ 如果发现它“变弱了”怎么办？

如果你在测试中发现 Skill 表现不佳（例如开始问问题了，或者漏掉了约束）：

1.  **加强语气**: 在 `SKILL.md` 的 System Instructions 中使用更强烈的措辞（如 "MUST", "NEVER"）。
2.  **增加反例**: 在 `Few-Shot Examples` 中添加一个新的“反面教材”，专门针对它犯的错误。
3.  **调整提示词**: 检查 Project Custom Instructions 是否被覆盖或冲突。
